{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dealing with imbalanced datasets, combining oversampling with VAE and undersampling to improve model recognition over all classes.  "
      ],
      "metadata": {
        "id": "qLO_siFYEPSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "1MsCtTA8GgkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOzC3QPArH_F"
      },
      "source": [
        "Import packages, classifiers and etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "GDNB_c5RrH_I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, make_scorer\n",
        "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import VAEOversampler."
      ],
      "metadata": {
        "id": "7qxBXk4fPiJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from VAEOversampler import VAEOversampler"
      ],
      "metadata": {
        "id": "DqyRUyWlvryO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data  \n",
        "You can load some dataset from Imbalanced Learn list (https://imbalanced-learn.org/stable/datasets/index.html) or use your own data.  \n"
      ],
      "metadata": {
        "id": "8UEMO2hTPztj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.datasets import fetch_datasets\n",
        "\n",
        "dset_name = 'satimage'\n",
        "dset = fetch_datasets()[dset_name]\n",
        "dset.data.shape\n",
        "\n",
        "print(sorted(Counter(dset.target).items()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnh_x70FwVCi",
        "outputId": "80020616-33fc-406e-e66f-d29de74c6d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(-1, 5809), (1, 626)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dset.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_SUvgVSByCD",
        "outputId": "8459fbec-91c6-4170-86bd-edbd4ce8c0ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 92., 115., 120., ..., 107., 113.,  87.],\n",
              "       [ 84., 102., 106., ...,  99., 104.,  79.],\n",
              "       [ 84., 102., 102., ...,  99., 104.,  79.],\n",
              "       ...,\n",
              "       [ 56.,  68.,  91., ...,  83.,  92.,  74.],\n",
              "       [ 56.,  68.,  87., ...,  83.,  92.,  70.],\n",
              "       [ 60.,  71.,  91., ...,  79., 108.,  92.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(dset.data)\n",
        "y = dset.target"
      ],
      "metadata": {
        "id": "SO2eKOKs7rGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y[y == -1] = 0"
      ],
      "metadata": {
        "id": "Tb09lFMxPS2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Original dataset shape %s' % Counter(y))\n",
        "print('Ratio->', round(Counter(y)[0]/Counter(y)[1], 1), ': 1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLogQr2rdjMU",
        "outputId": "61d51af4-4ab1-490f-a37a-d02061cd6804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape Counter({0: 5809, 1: 626})\n",
            "Ratio-> 9.3 : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split data into train and test partitions."
      ],
      "metadata": {
        "id": "hpLA_GmKSJwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "ZS-Dd0R9GbBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em7Um0N4rH_S"
      },
      "source": [
        "This is a simple function to undersample freely.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RUS\n",
        "\n",
        "def RUS(X_res, y_res, frac=1, minority_class_id=1, random_state=42):\n",
        "    X_res = pd.DataFrame(X_res)\n",
        "    X_res['Class'] = y_res  \n",
        "    \n",
        "    X_neg = X_res[y_res != minority_class_id].sample(frac=frac, random_state=random_state)\n",
        "    X_pos = X_res[y_res == minority_class_id].sample(frac=1)\n",
        "    \n",
        "    X_rus = pd.concat([X_neg, X_pos], ignore_index=True)\n",
        "\n",
        "    X_eq = X_rus.drop('Class', axis=1)\n",
        "    y_eq = X_rus['Class']\n",
        "\n",
        "    return X_eq, y_eq"
      ],
      "metadata": {
        "id": "1cdWcXE3Ofok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val(X, y, Xt, yt, random_state=42):\n",
        "    classifiers = {\n",
        "        \"CatBoostClassifier\": CatBoostClassifier(verbose=False, random_seed=random_state),\n",
        "        \"LGBMClassifier\": LGBMClassifier(random_state=random_state),\n",
        "        \"XGBClassifier\": XGBClassifier(random_state=random_state),\n",
        "        \"BaggingClassifier\": BaggingClassifier(random_state=random_state),\n",
        "        \"RandomForestClassifier\": RandomForestClassifier(random_state=random_state),\n",
        "    }\n",
        "    scores = []\n",
        "    predictions = []\n",
        "    for key, classifier in classifiers.items():\n",
        "        print('_' * 50)\n",
        "        name = key\n",
        "        classifier.fit(X, y)\n",
        "        print(\"Classifier: \", name)\n",
        "        y_pred = classifier.predict(Xt)\n",
        "        cm = confusion_matrix(yt, y_pred)\n",
        "        print(cm)\n",
        "        print('')\n",
        "        predictions.append(y_pred)\n",
        "        tn = cm[0,0]\n",
        "        fp = cm[0,1]\n",
        "        fn = cm[1,0]\n",
        "        tp = cm[1,1]\n",
        "        tnr = tn / (tn + fp)\n",
        "        tpr = tp / (tp + fn)\n",
        "        scores.append(tnr * tpr)\n",
        "        print('TNR:', round(tnr, 5))\n",
        "        print('TPR:', round(tpr, 5))\n",
        "        print('TNRxTPR:', round(tnr * tpr, 5))\n",
        "        print('G-mean:', round(np.sqrt(tnr * tpr), 5))\n",
        "\n",
        "    print('_' * 50)\n",
        "    print('Ensemble predictions (majority voting):')\n",
        "    predictions = np.sum(predictions, axis=0)\n",
        "    predictions[predictions < 3] = 0\n",
        "    predictions[predictions >= 3] = 1\n",
        "\n",
        "    cm = confusion_matrix(yt, predictions)\n",
        "    print(cm)\n",
        "    tn = cm[0,0]\n",
        "    fp = cm[0,1]\n",
        "    fn = cm[1,0]\n",
        "    tp = cm[1,1]\n",
        "    tnr = tn / (tn + fp)\n",
        "    tpr = tp / (tp + fn)\n",
        "    print('')\n",
        "    print('TNR:', round(tnr, 5))\n",
        "    print('TPR:', round(tpr, 5))\n",
        "    print('TNRxTPR:', round(tnr * tpr, 5))\n",
        "    print('G-mean:', round(np.sqrt(tnr * tpr), 5))\n",
        "    "
      ],
      "metadata": {
        "id": "1Ep1nUMCES98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ratio 1:1  \n",
        "Let's see classifiers scores when dataset is balanced.  \n"
      ],
      "metadata": {
        "id": "u53eaidjVlpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vae_sampler = VAEOversampler(epochs=50,\n",
        "                              intermediate_dim=512,\n",
        "                              batch_size=64,\n",
        "                              rescale=True,\n",
        "                              random_state=42,\n",
        "                              verbose=False)\n",
        "Xres, yres = vae_sampler.fit_resample(X_train, y_train, validation_data=[X_test, y_test])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b36d82-dfe8-422f-bc67-ed0ee80bd43b",
        "id": "B065rYa3wO-o"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130/130 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Resampled dataset shape %s' % Counter(yres))\n",
        "print('Ratio->  1 :', round(Counter(yres)[1]/Counter(yres)[0], 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOsNattyeSXh",
        "outputId": "3785fbee-89eb-4c1d-a7c3-e16dee7a54fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampled dataset shape Counter({1.0: 4647, 0.0: 4647})\n",
            "Ratio->  1 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "531ff526-a2cf-496e-9ca6-a39d5f792077",
        "id": "6BNffQSbwO-t"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__________________________________________________\n",
            "Classifier:  CatBoostClassifier\n",
            "[[1141   21]\n",
            " [  49   76]]\n",
            "\n",
            "TNR: 0.98193\n",
            "TPR: 0.608\n",
            "TNRxTPR: 0.59701\n",
            "G-mean: 0.77267\n",
            "__________________________________________________\n",
            "Classifier:  LGBMClassifier\n",
            "[[1140   22]\n",
            " [  41   84]]\n",
            "\n",
            "TNR: 0.98107\n",
            "TPR: 0.672\n",
            "TNRxTPR: 0.65928\n",
            "G-mean: 0.81196\n",
            "__________________________________________________\n",
            "Classifier:  XGBClassifier\n",
            "[[1139   23]\n",
            " [  42   83]]\n",
            "\n",
            "TNR: 0.98021\n",
            "TPR: 0.664\n",
            "TNRxTPR: 0.65086\n",
            "G-mean: 0.80676\n",
            "__________________________________________________\n",
            "Classifier:  BaggingClassifier\n",
            "[[1144   18]\n",
            " [  62   63]]\n",
            "\n",
            "TNR: 0.98451\n",
            "TPR: 0.504\n",
            "TNRxTPR: 0.49619\n",
            "G-mean: 0.70441\n",
            "__________________________________________________\n",
            "Classifier:  RandomForestClassifier\n",
            "[[1149   13]\n",
            " [  58   67]]\n",
            "\n",
            "TNR: 0.98881\n",
            "TPR: 0.536\n",
            "TNRxTPR: 0.53\n",
            "G-mean: 0.72801\n",
            "__________________________________________________\n",
            "Ensemble predictions (majority voting):\n",
            "[[1142   20]\n",
            " [  49   76]]\n",
            "\n",
            "TNR: 0.98279\n",
            "TPR: 0.608\n",
            "TNRxTPR: 0.59754\n",
            "G-mean: 0.773\n"
          ]
        }
      ],
      "source": [
        "train_val(Xres, yres, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Under/Oversampling combination  \n",
        "Now we can tuning the number of instances for each class to optimize metric.  \n"
      ],
      "metadata": {
        "id": "w9swp8C1wO-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xres, yres = vae_sampler.resample(X_train, y_train, sampling_strategy=.6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "152adb4b-751a-41ad-c30c-161b093f5cd1",
        "id": "T6benPDnCzym"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78/78 [==============================] - 1s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RUS\n",
        "\n",
        "X_eq, y_eq = RUS(Xres, yres, frac=.16)\n",
        "\n",
        "print('Resampled dataset shape %s' % Counter(y_eq))\n",
        "print('Ratio->  1 :', round(Counter(y_eq)[1]/Counter(y_eq)[0], 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b05f53a-776d-4560-dbe6-f14163438c12",
        "id": "7a1QqxB6Czyx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampled dataset shape Counter({1.0: 2988, 0.0: 744})\n",
            "Ratio->  1 : 4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1ca764e-548c-407f-b5a8-4b3fffdc1270",
        "id": "oAv7STUxCzy0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__________________________________________________\n",
            "Classifier:  CatBoostClassifier\n",
            "[[1031  131]\n",
            " [  18  107]]\n",
            "\n",
            "TNR: 0.88726\n",
            "TPR: 0.856\n",
            "TNRxTPR: 0.7595\n",
            "G-mean: 0.87149\n",
            "__________________________________________________\n",
            "Classifier:  LGBMClassifier\n",
            "[[1021  141]\n",
            " [  12  113]]\n",
            "\n",
            "TNR: 0.87866\n",
            "TPR: 0.904\n",
            "TNRxTPR: 0.79431\n",
            "G-mean: 0.89124\n",
            "__________________________________________________\n",
            "Classifier:  XGBClassifier\n",
            "[[1027  135]\n",
            " [   7  118]]\n",
            "\n",
            "TNR: 0.88382\n",
            "TPR: 0.944\n",
            "TNRxTPR: 0.83433\n",
            "G-mean: 0.91342\n",
            "__________________________________________________\n",
            "Classifier:  BaggingClassifier\n",
            "[[1039  123]\n",
            " [  24  101]]\n",
            "\n",
            "TNR: 0.89415\n",
            "TPR: 0.808\n",
            "TNRxTPR: 0.72247\n",
            "G-mean: 0.84998\n",
            "__________________________________________________\n",
            "Classifier:  RandomForestClassifier\n",
            "[[1045  117]\n",
            " [  16  109]]\n",
            "\n",
            "TNR: 0.89931\n",
            "TPR: 0.872\n",
            "TNRxTPR: 0.7842\n",
            "G-mean: 0.88555\n",
            "__________________________________________________\n",
            "Ensemble predictions (majority voting):\n",
            "[[1033  129]\n",
            " [  13  112]]\n",
            "\n",
            "TNR: 0.88898\n",
            "TPR: 0.896\n",
            "TNRxTPR: 0.79653\n",
            "G-mean: 0.89249\n"
          ]
        }
      ],
      "source": [
        "train_val(X_eq, y_eq, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBClassifier  \n",
        "  - G-mean: **0.91342**  \n"
      ],
      "metadata": {
        "id": "FJwegKpOWwE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://imbalanced-learn.org/stable/auto_examples/ensemble/plot_comparison_ensemble_classifier.html#sphx-glr-auto-examples-ensemble-plot-comparison-ensemble-classifier-py  \n",
        "\n",
        "In this web we can compare our results on 'satimage' dataset with some balanced versions of classical algorithms like: **BalancedBaggingClassifier**, **BalancedRandomForestClassifier**.  \n"
      ],
      "metadata": {
        "id": "Dww7zO8e6f9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://imbalanced-learn.org/stable/combine.html  \n",
        "Here we find two versions of SMOTE that combines over- and under-sampling: **SMOTEENN** and **SMOTETomek**."
      ],
      "metadata": {
        "id": "DDN2-yn2Nwex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross Validation  "
      ],
      "metadata": {
        "id": "d2dGPOafJJkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g_mean = make_scorer(geometric_mean_score)\n",
        "\n",
        "clf = XGBClassifier(random_state=42)\n",
        "\n",
        "cv_results = cross_validate(clf, X_eq, y_eq, scoring=g_mean, cv=10,\n",
        "                            return_estimator=True, n_jobs=-1)\n",
        "\n",
        "print(f\"G-mean CV: {cv_results['test_score'].mean():.3f} (+/-{cv_results['test_score'].std():.3f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz8mYmZFDRhS",
        "outputId": "7b64041d-53dc-4ae8-e268-8a3c14432dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G-mean CV: 0.928 (+/-0.014)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "for fold_id, cv_model in enumerate(cv_results['estimator']):\n",
        "    scores.append(geometric_mean_score(y_test, cv_model.predict(X_test)))\n",
        "    \n",
        "print(f\"G-mean CV (test): {np.mean(scores):.3f} (+/-{np.std(scores):.3f})\")"
      ],
      "metadata": {
        "id": "LsLl2bA23U9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510d24d1-d3e4-4d19-ce83-a9baee76748e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G-mean CV (test): 0.883 (+/-0.014)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification report  "
      ],
      "metadata": {
        "id": "tS3nvD_eNnkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = XGBClassifier(random_state=42).fit(X_eq, y_eq).predict(X_test)\n",
        "\n",
        "print(classification_report_imbalanced(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmWAOUOBMl8K",
        "outputId": "fcd4d64a-869c-4273-bbc1-507245d82d80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.99      0.88      0.94      0.94      0.91      0.83      1162\n",
            "          1       0.47      0.94      0.88      0.62      0.91      0.84       125\n",
            "\n",
            "avg / total       0.94      0.89      0.94      0.91      0.91      0.83      1287\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References  \n",
        "\n",
        "  - Classification with Imbalanced Datasets:  \n",
        "    https://sci2s.ugr.es/imbalanced  \n",
        "  - Computer Vision:  Models, Learning, and Inference (Simon J.D. Prince):  \n",
        "    http://www.computervisionmodels.com/  \n",
        "  - Oversampling with VAEs:  \n",
        "    https://towardsdatascience.com/oversampling-with-vaes-e410887fe51  \n"
      ],
      "metadata": {
        "id": "RydFSMjOoD87"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}