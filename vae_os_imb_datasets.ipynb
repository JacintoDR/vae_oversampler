{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLO_siFYEPSg"
   },
   "source": [
    "# Dealing with imbalanced datasets, combining oversampling with VAE and undersampling to improve over all classes model recognition.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1MsCtTA8GgkS"
   },
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOzC3QPArH_F"
   },
   "source": [
    "Import packages, classifiers and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "GDNB_c5RrH_I"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qxBXk4fPiJx"
   },
   "source": [
    "Import VAEOversampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DqyRUyWlvryO"
   },
   "outputs": [],
   "source": [
    "from VAEOversampler import VAEOversampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UEMO2hTPztj"
   },
   "source": [
    "## Loading data  \n",
    "You can load some dataset from Imbalanced Learn list (https://imbalanced-learn.org/stable/datasets/index.html) or use your own data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xnh_x70FwVCi",
    "outputId": "80020616-33fc-406e-e66f-d29de74c6d9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-1, 5809), (1, 626)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.datasets import fetch_datasets\n",
    "\n",
    "dset_name = 'satimage'\n",
    "dset = fetch_datasets()[dset_name]\n",
    "dset.data.shape\n",
    "\n",
    "print(sorted(Counter(dset.target).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_SUvgVSByCD",
    "outputId": "8459fbec-91c6-4170-86bd-edbd4ce8c0ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 92., 115., 120., ..., 107., 113.,  87.],\n",
       "       [ 84., 102., 106., ...,  99., 104.,  79.],\n",
       "       [ 84., 102., 102., ...,  99., 104.,  79.],\n",
       "       ...,\n",
       "       [ 56.,  68.,  91., ...,  83.,  92.,  74.],\n",
       "       [ 56.,  68.,  87., ...,  83.,  92.,  70.],\n",
       "       [ 60.,  71.,  91., ...,  79., 108.,  92.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SO2eKOKs7rGJ"
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(dset.data)\n",
    "y = dset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Tb09lFMxPS2J"
   },
   "outputs": [],
   "source": [
    "y[y == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLogQr2rdjMU",
    "outputId": "61d51af4-4ab1-490f-a37a-d02061cd6804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 5809, 1: 626})\n",
      "Ratio-> 9.3 : 1\n"
     ]
    }
   ],
   "source": [
    "print('Original dataset shape %s' % Counter(y))\n",
    "print('Ratio->', round(Counter(y)[0]/Counter(y)[1], 1), ': 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpLA_GmKSJwN"
   },
   "source": [
    "We split data into train and test partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZS-Dd0R9GbBY"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Em7Um0N4rH_S"
   },
   "source": [
    "This is a simple function to undersample freely.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1cdWcXE3Ofok"
   },
   "outputs": [],
   "source": [
    "# RUS\n",
    "\n",
    "def RUS(X_res, y_res, frac=1, minority_class_id=1, random_state=42):\n",
    "    X_res = pd.DataFrame(X_res)\n",
    "    X_res['Class'] = y_res  \n",
    "    \n",
    "    X_neg = X_res[y_res != minority_class_id].sample(frac=frac, random_state=random_state)\n",
    "    X_pos = X_res[y_res == minority_class_id].sample(frac=1, random_state=random_state)\n",
    "    \n",
    "    X_rus = pd.concat([X_neg, X_pos], ignore_index=True)\n",
    "\n",
    "    X_eq = X_rus.drop('Class', axis=1)\n",
    "    y_eq = X_rus['Class']\n",
    "\n",
    "    return X_eq, y_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1Ep1nUMCES98"
   },
   "outputs": [],
   "source": [
    "def train_val(X, y, Xt, yt, random_state=42):\n",
    "    classifiers = {\n",
    "        \"CatBoostClassifier\": CatBoostClassifier(verbose=False, random_seed=random_state),\n",
    "        \"LGBMClassifier\": LGBMClassifier(random_state=random_state),\n",
    "        \"XGBClassifier\": XGBClassifier(random_state=random_state),\n",
    "        \"BaggingClassifier\": BaggingClassifier(random_state=random_state),\n",
    "        \"RandomForestClassifier\": RandomForestClassifier(random_state=random_state),\n",
    "    }\n",
    "    scores = []\n",
    "    predictions = []\n",
    "    for key, classifier in classifiers.items():\n",
    "        print('_' * 50)\n",
    "        name = key\n",
    "        classifier.fit(X, y)\n",
    "        print(\"Classifier: \", name)\n",
    "        y_pred = classifier.predict(Xt)\n",
    "        cm = confusion_matrix(yt, y_pred)\n",
    "        print(cm)\n",
    "        print('')\n",
    "        predictions.append(y_pred)\n",
    "        tn = cm[0,0]\n",
    "        fp = cm[0,1]\n",
    "        fn = cm[1,0]\n",
    "        tp = cm[1,1]\n",
    "        tnr = tn / (tn + fp)\n",
    "        tpr = tp / (tp + fn)\n",
    "        scores.append(tnr * tpr)\n",
    "        print('TNR:', round(tnr, 5))\n",
    "        print('TPR:', round(tpr, 5))\n",
    "        print('TNRxTPR:', round(tnr * tpr, 5))\n",
    "        print('G-mean:', round(np.sqrt(tnr * tpr), 5))\n",
    "\n",
    "    print('_' * 50)\n",
    "    print('Ensemble predictions (majority voting):')\n",
    "    predictions = np.sum(predictions, axis=0)\n",
    "    predictions[predictions < 3] = 0\n",
    "    predictions[predictions >= 3] = 1\n",
    "\n",
    "    cm = confusion_matrix(yt, predictions)\n",
    "    print(cm)\n",
    "    tn = cm[0,0]\n",
    "    fp = cm[0,1]\n",
    "    fn = cm[1,0]\n",
    "    tp = cm[1,1]\n",
    "    tnr = tn / (tn + fp)\n",
    "    tpr = tp / (tp + fn)\n",
    "    print('')\n",
    "    print('TNR:', round(tnr, 5))\n",
    "    print('TPR:', round(tpr, 5))\n",
    "    print('TNRxTPR:', round(tnr * tpr, 5))\n",
    "    print('G-mean:', round(np.sqrt(tnr * tpr), 5))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u53eaidjVlpk"
   },
   "source": [
    "## Ratio 1:1  \n",
    "Let's see classifiers scores when dataset is balanced.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B065rYa3wO-o",
    "outputId": "a6b36d82-dfe8-422f-bc67-ed0ee80bd43b"
   },
   "outputs": [],
   "source": [
    "vae_sampler = VAEOversampler(epochs=500,\n",
    "                              intermediate_dim=512,\n",
    "                              batch_size=64,\n",
    "                              rescale=True,\n",
    "                              random_state=42,\n",
    "                              verbose=False)\n",
    "Xres, yres = vae_sampler.fit_resample(X_train, y_train, validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOsNattyeSXh",
    "outputId": "3785fbee-89eb-4c1d-a7c3-e16dee7a54fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1.0: 4647, 0.0: 4647})\n",
      "Ratio->  1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Resampled dataset shape %s' % Counter(yres))\n",
    "print('Ratio->  1 :', round(Counter(yres)[1]/Counter(yres)[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6BNffQSbwO-t",
    "outputId": "531ff526-a2cf-496e-9ca6-a39d5f792077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "Classifier:  CatBoostClassifier\n",
      "[[1143   19]\n",
      " [  45   80]]\n",
      "\n",
      "TNR: 0.98365\n",
      "TPR: 0.64\n",
      "TNRxTPR: 0.62954\n",
      "G-mean: 0.79343\n",
      "__________________________________________________\n",
      "Classifier:  LGBMClassifier\n",
      "[[1137   25]\n",
      " [  45   80]]\n",
      "\n",
      "TNR: 0.97849\n",
      "TPR: 0.64\n",
      "TNRxTPR: 0.62623\n",
      "G-mean: 0.79135\n",
      "__________________________________________________\n",
      "Classifier:  XGBClassifier\n",
      "[[1142   20]\n",
      " [  43   82]]\n",
      "\n",
      "TNR: 0.98279\n",
      "TPR: 0.656\n",
      "TNRxTPR: 0.64471\n",
      "G-mean: 0.80294\n",
      "__________________________________________________\n",
      "Classifier:  BaggingClassifier\n",
      "[[1144   18]\n",
      " [  62   63]]\n",
      "\n",
      "TNR: 0.98451\n",
      "TPR: 0.504\n",
      "TNRxTPR: 0.49619\n",
      "G-mean: 0.70441\n",
      "__________________________________________________\n",
      "Classifier:  RandomForestClassifier\n",
      "[[1149   13]\n",
      " [  59   66]]\n",
      "\n",
      "TNR: 0.98881\n",
      "TPR: 0.528\n",
      "TNRxTPR: 0.52209\n",
      "G-mean: 0.72256\n",
      "__________________________________________________\n",
      "Ensemble predictions (majority voting):\n",
      "[[1143   19]\n",
      " [  51   74]]\n",
      "\n",
      "TNR: 0.98365\n",
      "TPR: 0.592\n",
      "TNRxTPR: 0.58232\n",
      "G-mean: 0.7631\n"
     ]
    }
   ],
   "source": [
    "train_val(Xres, yres, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9swp8C1wO-w"
   },
   "source": [
    "## Under/Oversampling combination  \n",
    "Now we can tuning the number of instances for each class to optimize metric.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6benPDnCzym",
    "outputId": "152adb4b-751a-41ad-c30c-161b093f5cd1"
   },
   "outputs": [],
   "source": [
    "Xres, yres = vae_sampler.resample(X_train, y_train, sampling_strategy=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7a1QqxB6Czyx",
    "outputId": "2b05f53a-776d-4560-dbe6-f14163438c12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1.0: 3403, 0.0: 674})\n",
      "Ratio->  1 : 5.0\n"
     ]
    }
   ],
   "source": [
    "# RUS\n",
    "\n",
    "X_eq, y_eq = RUS(Xres, yres, frac=.145)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_eq))\n",
    "print('Ratio->  1 :', round(Counter(y_eq)[1]/Counter(y_eq)[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAv7STUxCzy0",
    "outputId": "a1ca764e-548c-407f-b5a8-4b3fffdc1270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "Classifier:  CatBoostClassifier\n",
      "[[1014  148]\n",
      " [  16  109]]\n",
      "\n",
      "TNR: 0.87263\n",
      "TPR: 0.872\n",
      "TNRxTPR: 0.76094\n",
      "G-mean: 0.87232\n",
      "__________________________________________________\n",
      "Classifier:  LGBMClassifier\n",
      "[[1008  154]\n",
      " [   7  118]]\n",
      "\n",
      "TNR: 0.86747\n",
      "TPR: 0.944\n",
      "TNRxTPR: 0.81889\n",
      "G-mean: 0.90493\n",
      "__________________________________________________\n",
      "Classifier:  XGBClassifier\n",
      "[[1021  141]\n",
      " [  10  115]]\n",
      "\n",
      "TNR: 0.87866\n",
      "TPR: 0.92\n",
      "TNRxTPR: 0.80836\n",
      "G-mean: 0.89909\n",
      "__________________________________________________\n",
      "Classifier:  BaggingClassifier\n",
      "[[1034  128]\n",
      " [  23  102]]\n",
      "\n",
      "TNR: 0.88985\n",
      "TPR: 0.816\n",
      "TNRxTPR: 0.72611\n",
      "G-mean: 0.85212\n",
      "__________________________________________________\n",
      "Classifier:  RandomForestClassifier\n",
      "[[1033  129]\n",
      " [  14  111]]\n",
      "\n",
      "TNR: 0.88898\n",
      "TPR: 0.888\n",
      "TNRxTPR: 0.78942\n",
      "G-mean: 0.88849\n",
      "__________________________________________________\n",
      "Ensemble predictions (majority voting):\n",
      "[[1027  135]\n",
      " [  11  114]]\n",
      "\n",
      "TNR: 0.88382\n",
      "TPR: 0.912\n",
      "TNRxTPR: 0.80604\n",
      "G-mean: 0.8978\n"
     ]
    }
   ],
   "source": [
    "train_val(X_eq, y_eq, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJwegKpOWwE0"
   },
   "source": [
    "LGBMClassifier  \n",
    "  - G-mean: **0.90493**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dww7zO8e6f9u"
   },
   "source": [
    "https://imbalanced-learn.org/stable/auto_examples/ensemble/plot_comparison_ensemble_classifier.html#sphx-glr-auto-examples-ensemble-plot-comparison-ensemble-classifier-py  \n",
    "\n",
    "In this web we can compare our results on 'satimage' dataset with some balanced versions of classical algorithms like: **BalancedBaggingClassifier**, **BalancedRandomForestClassifier**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDN2-yn2Nwex"
   },
   "source": [
    "https://imbalanced-learn.org/stable/combine.html  \n",
    "Here we find two versions of SMOTE that combines over- and under-sampling: **SMOTEENN** and **SMOTETomek**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2dGPOafJJkw"
   },
   "source": [
    "## Cross Validation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uz8mYmZFDRhS",
    "outputId": "7b64041d-53dc-4ae8-e268-8a3c14432dad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G-mean CV: 0.927 (+/-0.019)\n"
     ]
    }
   ],
   "source": [
    "g_mean = make_scorer(geometric_mean_score)\n",
    "\n",
    "clf = LGBMClassifier(random_state=42)\n",
    "\n",
    "cv_results = cross_validate(clf, X_eq, y_eq, scoring=g_mean, cv=10,\n",
    "                            return_estimator=True, n_jobs=-1)\n",
    "\n",
    "print(f\"G-mean CV: {cv_results['test_score'].mean():.3f} (+/-{cv_results['test_score'].std():.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LsLl2bA23U9D",
    "outputId": "510d24d1-d3e4-4d19-ce83-a9baee76748e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G-mean CV (test): 0.891 (+/-0.005)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for fold_id, cv_model in enumerate(cv_results['estimator']):\n",
    "    scores.append(geometric_mean_score(y_test, cv_model.predict(X_test)))\n",
    "    \n",
    "print(f\"G-mean CV (test): {np.mean(scores):.3f} (+/-{np.std(scores):.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tS3nvD_eNnkF"
   },
   "source": [
    "Classification report  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zmWAOUOBMl8K",
    "outputId": "fcd4d64a-869c-4273-bbc1-507245d82d80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      0.87      0.94      0.93      0.90      0.81      1162\n",
      "          1       0.43      0.94      0.87      0.59      0.90      0.83       125\n",
      "\n",
      "avg / total       0.94      0.87      0.94      0.89      0.90      0.81      1287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = LGBMClassifier(random_state=42).fit(X_eq, y_eq).predict(X_test)\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RydFSMjOoD87"
   },
   "source": [
    "## References  \n",
    "\n",
    "  - Classification with Imbalanced Datasets:  \n",
    "    https://sci2s.ugr.es/imbalanced  \n",
    "  - Computer Vision:  Models, Learning, and Inference (Simon J.D. Prince):  \n",
    "    http://www.computervisionmodels.com/  \n",
    "  - Oversampling with VAEs:  \n",
    "    https://towardsdatascience.com/oversampling-with-vaes-e410887fe51  \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
